{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9f4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span, Doc, Token, DocBin\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1639219",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b4aaa",
   "metadata": {},
   "source": [
    "## Training the entity recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8581d80",
   "metadata": {},
   "source": [
    "Previously we saw how to use rules to recognize new entities. However, a rule-based approach can require very complicated rules and still may be quite brittle.\n",
    "\n",
    "A statistical model can be very helpful in many instances. And of course only a statistical model can do things like sentiment analysis.\n",
    "\n",
    "A rules-based approach is mostly helpful for preliminary processing and bulk-labeling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153aba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"iPhone X is coming\")\n",
    "doc1.ents = [Span(doc1, 0, 2, label='GADGET')]\n",
    "# the model needs to see examples where entities are labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a29fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp('I need a new phone! Any tips?')\n",
    "doc2.ents = []\n",
    "# but the model also needs unlabeled examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633e209",
   "metadata": {},
   "source": [
    "## DocBins to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee1dd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(\"The banana phone rings, but the Android phone beeps\")\n",
    "doc3.ents = [Span(doc3, 7, 9, label='GADGET')]\n",
    "doc4 = nlp(\"This ChromeBook is very cool\")\n",
    "doc4.ents = [Span(doc4, 1, 2, label='GADGET')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce0a36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc1, doc2, doc3, doc4]\n",
    "random.shuffle(docs)\n",
    "train_docs = docs[:len(docs) // 2]\n",
    "test_docs = docs[len(docs) // 2 + 1:]\n",
    "# create efficient container for docs to be used in training of model\n",
    "train_docbin = DocBin()\n",
    "for doc in train_docs: train_docbin.add(doc)\n",
    "train_docbin.to_disk('chap4_train.spacy')\n",
    "test_docbin = DocBin()\n",
    "for doc in test_docs: test_docbin.add(doc)\n",
    "test_docbin.to_disk('chap4_test.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c832cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conll, conllu, and iob are other file extensions for corpora\n",
    "# spacy convert also allows conversion from spacy's old json format\n",
    "# !python -m spacy convert <fname> <to_dir>\n",
    "# converts file fname with one of those formats to the spacy format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169d339",
   "metadata": {},
   "source": [
    "## making a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ad0de4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Generated config template specific for your use case\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "chap4_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train chap4_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 10:46:16.054133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-01 10:46:16.054179: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config -F ./chap4_config.cfg --lang en --pipeline ner,tok2vec\n",
    "# the --pipeline args are comma-separated\n",
    "# the -F arg means to overwrite the config file if it already exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415942e",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80ebb5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: chap4_out\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00      8.83    0.00    0.00    0.00    0.00\n",
      "200     200          0.76    126.49    0.00    0.00    0.00    0.00\n",
      "400     400          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "600     600          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "800     800          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1000    1000          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1200    1200          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1400    1400          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1600    1600          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "[+] Saved pipeline to output directory\n",
      "chap4_out\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 10:47:08.650055: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-01 10:47:08.650092: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-01 10:47:12,618] [INFO] Set up nlp object from config\n",
      "[2022-05-01 10:47:12,627] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-01 10:47:12,627] [INFO] Created vocabulary\n",
      "[2022-05-01 10:47:12,627] [INFO] Finished initializing nlp object\n",
      "[2022-05-01 10:47:12,707] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ./chap4_config.cfg --output ./chap4_out --paths.train chap4_train.spacy --paths.dev chap4_test.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae36338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('chap4_out/model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04979d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Android 11 vs iPhone 8 vs kumquat phone: what's the diff?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18236138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android 11', 'GADGET')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.text, x.label_) for x in doc.ents]\n",
    "# note that the trained model can now find GADGET entities on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a436395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy package /chap4_out/model-best ./packages --name gadget_labeler --version 1.0.0\n",
    "# ! cd ./packages/en_gadget_labeler\n",
    "# python -m pip install dist/en_gadget_labeler-1.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b69e7",
   "metadata": {},
   "source": [
    "## Problems and solutions in model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889347e",
   "metadata": {},
   "source": [
    "**Problem:** model forgets how to apply one label when learning how to apply another (e.g., it learns how to label GADGET and forgets how to label FRUIT)\n",
    "\n",
    "**Solution:** Mix in FRUIT examples with the GADGET examples, especially FRUIT examples that were previously labeled correctly. This way the model will learn both at the same time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef520e0d",
   "metadata": {},
   "source": [
    "**Problem:** spaCy can't distinguish SQUASH from LEAFY_GREEN\n",
    "\n",
    "**Solution:** Try having a less granular category, like VEGETABLE. \n",
    "\n",
    "Models fit based on local context of examples - if there are too few examples of local context, it will overfit to the tokens surrounding what few examples it saw."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755ee5e",
   "metadata": {},
   "source": [
    "**Problem:** But I need to be able to distinguish SQUASH from LEAFY_GREEN!\n",
    "\n",
    "**Solution:** Use rules to break down general labels into subcategories. Like maybe you can just have a lookup table of squashes and a lookup table of leafy greens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
